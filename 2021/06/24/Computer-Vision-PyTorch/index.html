<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;ly1998117.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:true,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:true,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script>
<meta name="description" content="Task use image classification tasks to learn about convolutional neural networks, and then see how pre-trained networks and transfer learning can improve our models and solve real-world problems.">
<meta property="og:type" content="article">
<meta property="og:title" content="Computer vision with PyTorch (Dense &amp;&amp; Convolutional layers)">
<meta property="og:url" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/index.html">
<meta property="og:site_name" content="LiuYang&#39;s Blog">
<meta property="og:description" content="Task use image classification tasks to learn about convolutional neural networks, and then see how pre-trained networks and transfer learning can improve our models and solve real-world problems.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/mFBCV.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/1.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/2.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/3.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/4.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/5.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/dense-multilayer-network.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/6.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/multilayer-network-layers.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/7.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/8.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/9.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/10.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/11.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/cnn-pyramid.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/12.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/13.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/14.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/15.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/16.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/17.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/18.png">
<meta property="article:published_time" content="2021-06-24T15:18:49.000Z">
<meta property="article:modified_time" content="2021-06-28T02:56:18.834Z">
<meta property="article:author" content="LiuYang">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/mFBCV.png">


<link rel="canonical" href="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;https:&#x2F;&#x2F;ly1998117.github.io&#x2F;2021&#x2F;06&#x2F;24&#x2F;Computer-Vision-PyTorch&#x2F;&quot;,&quot;path&quot;:&quot;2021&#x2F;06&#x2F;24&#x2F;Computer-Vision-PyTorch&#x2F;&quot;,&quot;title&quot;:&quot;Computer vision with PyTorch (Dense &amp;&amp; Convolutional layers)&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>Computer vision with PyTorch (Dense && Convolutional layers) | LiuYang's Blog</title><script src="/js/config.js"></script>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">LiuYang's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">24</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">11</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#task"><span class="nav-number">1.</span> <span class="nav-text">Task</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction-to-image-data"><span class="nav-number">2.</span> <span class="nav-text">Introduction to image data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#import-packages-and-load-the-mnist-dataset"><span class="nav-number">3.</span> <span class="nav-text">Import packages and load the MNIST Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#training-a-dense-neural-network"><span class="nav-number">4.</span> <span class="nav-text">Training a dense neural network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#fully-connected-dense-neural-networks"><span class="nav-number">4.1.</span> <span class="nav-text">Fully-connected dense neural networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#training-the-network"><span class="nav-number">4.2.</span> <span class="nav-text">Training the network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#visualize-history-to-better-understand-our-model-training"><span class="nav-number">4.3.</span> <span class="nav-text">visualize history to better understand our model training</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#visualizing-network-weights"><span class="nav-number">4.4.</span> <span class="nav-text">Visualizing network weights</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#training-a-multi-layered-perceptron"><span class="nav-number">5.</span> <span class="nav-text">Training a multi-Layered perceptron</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#network-definition"><span class="nav-number">5.1.</span> <span class="nav-text">Network Definition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#class-based-network-definitions"><span class="nav-number">5.2.</span> <span class="nav-text">Class-based network definitions</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#convolutional-neural-network"><span class="nav-number">6.</span> <span class="nav-text">convolutional neural network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#convolutional-filters"><span class="nav-number">6.1.</span> <span class="nav-text">Convolutional filters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#covolutional-layers"><span class="nav-number">6.2.</span> <span class="nav-text">Covolutional layers</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#multi-layered-cnns-and-pooling-layers"><span class="nav-number">7.</span> <span class="nav-text">Multi-layered CNNs and pooling layers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#playing-with-real-images-from-the-cifar-10-dataset"><span class="nav-number">8.</span> <span class="nav-text">Playing with real images from the CIFAR-10 dataset</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pre-trained-models-and-transfer-learning"><span class="nav-number">8.1.</span> <span class="nav-text">Pre-trained models and transfer learning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#playing-with-cats-vs.-dogs-dataset"><span class="nav-number">9.</span> <span class="nav-text">Playing with Cats vs. Dogs Dataset</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#pre-trained-models"><span class="nav-number">9.1.</span> <span class="nav-text">pre-trained models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#extracting-vgg-features"><span class="nav-number">9.2.</span> <span class="nav-text">Extracting VGG features</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#transfer-learning-using-one-vgg-network"><span class="nav-number">9.3.</span> <span class="nav-text">Transfer learning using one VGG network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fine-tuning-transfer-learning"><span class="nav-number">9.4.</span> <span class="nav-text">Fine-tuning transfer learning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#other-computer-vision-models"><span class="nav-number">10.</span> <span class="nav-text">Other computer vision models</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiuYang"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">LiuYang</p>
  <div class="site-description" itemprop="description">人与人的悲欢并不相通</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">46</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.macwk.com/" title="https:www.macwk.com&#x2F;" rel="noopener" target="_blank">Macwk</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ly1998117.github.io/2021/06/24/Computer-Vision-PyTorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LiuYang">
      <meta itemprop="description" content="人与人的悲欢并不相通">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiuYang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Computer vision with PyTorch (Dense && Convolutional layers)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-24 23:18:49" itemprop="dateCreated datePublished" datetime="2021-06-24T23:18:49+08:00">2021-06-24</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-06-28 10:56:18" itemprop="dateModified" datetime="2021-06-28T10:56:18+08:00">2021-06-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/PyTorch/" itemprop="url" rel="index"><span itemprop="name">PyTorch</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>32k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>29 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="task">Task</h2>
<p>use image classification tasks to learn about convolutional neural networks, and then see how pre-trained networks and transfer learning can improve our models and solve real-world problems.</p>
<span id="more"></span>
<h2 id="introduction-to-image-data">Introduction to image data</h2>
<p>In computer vision, we normally solve one of the following problems:</p>
<ul>
<li><strong>Image Classification</strong> the simplest task, when we need to classify an image into one of many pre-defined categories, for example, distinguish a cat from a dog on a photograph, or recognize a handwritten digit.</li>
<li><strong>Object Detection</strong> a bit more difficult task, in which we need to find known objects on the picture and localize them, i.e. return the <strong>bounding box</strong> for each of recognized objects.</li>
<li><strong>Segmentation</strong> similar to object detection, but instead of giving bounding box we need to return an exact pixel map outlining each of the recognized objects.</li>
</ul>
<p><img src="mFBCV.png" alt="mFBCV" style="zoom:80%;" /></p>
<p>Multi-dimensional arrays are also called <strong>tensors</strong>. Using tensors to represent images also has an advantage, because we can use an extra dimension to store a sequence of images. For example, to represent a video fragment consisting of 200 frames with 800x600 dimension, we may use the tensor of size 200x3x600x800.</p>
<h2 id="import-packages-and-load-the-mnist-dataset">Import packages and load the MNIST Dataset</h2>
<p>we are using the well-known <a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/mnist/">MNIST</a> dataset of handwritten digits, available through <code>torchvison.datasets.MNIST</code> in PyTorch. The dataset object returns the data in the form of Python Imagine Library (PIL) images, which we convert to tensors by passing a <code>transform=ToTensor()</code> parameter.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor</span><br><span class="line"></span><br><span class="line">training_data = datasets.MNIST(</span><br><span class="line">	root=<span class="string">&#x27;data&#x27;</span>,</span><br><span class="line">  train=<span class="literal">True</span>,</span><br><span class="line">  download=<span class="literal">False</span>,</span><br><span class="line">  transform=ToTensor()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_data = datasets.MNIST(</span><br><span class="line">	root=<span class="string">&#x27;data&#x27;</span>,</span><br><span class="line">  train=<span class="literal">False</span>,</span><br><span class="line">  download=<span class="literal">False</span>,</span><br><span class="line">  transform=ToTensor()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><img src="1.png" alt="1" style="zoom:60%;" /></p>
<blockquote>
<p>If you are planning to load your own images, it is important to make sure that all values are scaled to the range <a target="_blank" rel="noopener" href="https://docs.microsoft.com/zh-cn/learn/modules/intro-computer-vision-pytorch/2-image-data"><strong>0 - 1</strong></a> before we start training a neural network.</p>
</blockquote>
<h2 id="training-a-dense-neural-network">Training a dense neural network</h2>
<p>The handwritten digit recognition is a classification problem. We will start with the simplest possible approach for image classification - a fully-connected neural network (which is also called a <em>perceptron</em>).</p>
<h3 id="fully-connected-dense-neural-networks">Fully-connected dense neural networks</h3>
<p>A basic <strong>neural network</strong> in PyTorch consists of a number of <strong>layers</strong>. The simplest network would include just one fully-connected layer, which is called <strong>Linear</strong> layer, with 784 inputs (one input for each pixel of the input image) and 10 outputs (one output for each class).</p>
<p><img src="2.png" alt="2" style="zoom:30%;" /></p>
<p>the dimension of our digit images is 1×28×281×28×28. Because the input dimension of a fully-connected layer is 784, we need to insert another layer into the network, called <strong>Flatten</strong>, to change tensor shape from 1×28×281×28×28 to 784784.</p>
<p>We want nn-th output of the network to return the probability of the input digit being equal to nn. <strong>Because the output of a fully-connected layer is not normalized to be between 0 and 1, it cannot be thought of as probability</strong>. To turn it into a probability we need to apply another layer called <strong>Softmax</strong>.</p>
<p>In PyTorch, it is easier to use <strong>LogSoftmax</strong> function, which will also compute logarithms of output probabilities. To turn the output vector into the actual probabilities, we need to take <strong>torch.exp</strong> of the output.</p>
<p><img src="3.png" alt="3" style="zoom:30%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">        nn.Flatten(), </span><br><span class="line">        nn.Linear(<span class="number">784</span>,<span class="number">10</span>), <span class="comment"># 784 inputs, 10 outputs</span></span><br><span class="line">        nn.LogSoftmax())</span><br></pre></td></tr></table></figure>
<h3 id="training-the-network">Training the network</h3>
<blockquote>
<p>The training process steps are as follows:</p>
<ol type="1">
<li>We take a minibatch from the input dataset, which consists of input data (features) and expected result (label).</li>
<li>We calculate the predicted result for this minibatch.</li>
<li>The difference between this result and expected result is calculated using a special function called the <strong>loss function</strong></li>
<li>We calculate the gradients of this loss function with respect to model weights (parameters), which are then used to adjust the weights to optimize the performance of the network. The amount of adjustment is controlled by a parameter called <strong>learning rate</strong>, and the details of optimization algorithm are defined in the <strong>optimizer</strong> object.</li>
<li>We repeat those steps until the whole dataset is processed. One complete pass through the dataset is called <strong>an epoch</strong>.</li>
</ol>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span>(<span class="params">self, epoch, lr=<span class="number">1e-2</span>, optimizer=<span class="literal">None</span></span>):</span></span><br><span class="line">  optimizer = optimizer <span class="keyword">if</span> optimizer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> torch.optim.Adam(model.parameters(), lr=lr)</span><br><span class="line">  res = &#123;<span class="string">&#x27;train_loss&#x27;</span>: [], <span class="string">&#x27;train_acc&#x27;</span>: [], <span class="string">&#x27;val_loss&#x27;</span>: [], <span class="string">&#x27;val_acc&#x27;</span>: []&#125;</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, epoch + <span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;epoch: <span class="subst">&#123;i&#125;</span>\n---------------------------------&quot;</span>)</span><br><span class="line">    self.model.train()</span><br><span class="line">    total_loss, acc, count = <span class="number">0</span>, <span class="number">0</span>, <span class="built_in">len</span>(self.training_dataloader.dataset)</span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.training_dataloader):</span><br><span class="line">      pred_y = self.model(X)</span><br><span class="line">      loss = self.loss_fn(pred_y, y)</span><br><span class="line">      optimizer.zero_grad()</span><br><span class="line">      loss.backward()</span><br><span class="line">      optimizer.step()</span><br><span class="line">      total_loss += loss.item()</span><br><span class="line">      acc += (pred_y.argmax(<span class="number">1</span>) == y).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">      <span class="keyword">if</span> batch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;loss: <span class="subst">&#123;loss:&gt;5f&#125;</span>    [<span class="subst">&#123;batch * self.batch_size&#125;</span>/<span class="subst">&#123;count&#125;</span>]&quot;</span>)</span><br><span class="line">        res[<span class="string">&#x27;train_loss&#x27;</span>].append(total_loss / count * self.batch_size)</span><br><span class="line">        res[<span class="string">&#x27;train_acc&#x27;</span>].append(acc / count)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;train_loss: <span class="subst">&#123;total_loss / count * self.batch_size :&gt;5f&#125;</span>   train_acc: <span class="subst">&#123;acc / count:&gt;5f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        total_loss, acc, count = <span class="number">0</span>, <span class="number">0</span>, <span class="built_in">len</span>(self.test_dataloader.dataset)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">          <span class="keyword">for</span> X, y <span class="keyword">in</span> self.test_dataloader:</span><br><span class="line">            pred_y = self.model(X)</span><br><span class="line">            loss = self.loss_fn(pred_y, y)</span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            acc += (pred_y.argmax(<span class="number">1</span>) == y).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">            res[<span class="string">&#x27;val_loss&#x27;</span>].append(total_loss / count * self.batch_size)</span><br><span class="line">            res[<span class="string">&#x27;val_acc&#x27;</span>].append(acc / count)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;val_loss: <span class="subst">&#123;total_loss / count * self.batch_size:&gt;5f&#125;</span>  val_acc: <span class="subst">&#123;acc / count:&gt;5f&#125;</span> \n &quot;</span>)</span><br><span class="line"></span><br><span class="line">     <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<ul>
<li>Switch the network to training mode (<code>net.train()</code>)</li>
<li>Go over all batches in the dataset, and for each batch do the following:
<ul>
<li>compute predictions made by the network on this batch (<code>out</code>)</li>
<li>compute <code>loss</code>, which is the discrepancy between predicted and expected values</li>
<li>try to minimize the loss by adjusting weights of the network (<code>optimizer.step()</code>)</li>
<li>compute the number of correctly predicted cases (<strong>accuracy</strong>)</li>
</ul></li>
</ul>
<h3 id="visualize-history-to-better-understand-our-model-training">visualize history to better understand our model training</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">13</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot(hist[<span class="string">&#x27;train_acc&#x27;</span>], label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.plot(hist[<span class="string">&#x27;val_acc&#x27;</span>], label=<span class="string">&#x27;Validation acc&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.plot(hist[<span class="string">&#x27;train_loss&#x27;</span>], label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line">plt.plot(hist[<span class="string">&#x27;val_loss&#x27;</span>], label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="4.png" alt="4" style="zoom:50%;" /></p>
<blockquote>
<p>The diagram on the left shows the <code>training accuracy</code> increasing (which corresponds to the network learning to classify our training data better and better), while <code>validation accuracy</code> starts to fall. The diagram on the right show the <code>training loss</code> and <code>validation loss</code>, you can see the <code>training loss</code> decreasing (meaning its performing better) and the <code>validation loss</code> increasing (meaning its performing worse). These graphs would indicate the model is <strong>overfitted</strong>.</p>
</blockquote>
<h3 id="visualizing-network-weights">Visualizing network weights</h3>
<p>multiplying the initial image by a weight matrix allowing us to visualize the network weights with a bit of added logic.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">    weight_tensor = <span class="built_in">next</span>(self.model.parameters())</span><br><span class="line">    fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">10</span>, figsize=(<span class="number">20</span>,<span class="number">4</span>))</span><br><span class="line">    <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(weight_tensor):</span><br><span class="line">        ax[i].imshow(x.view(<span class="number">28</span>, <span class="number">28</span>).detach())</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="5.png" alt="5" style="zoom:50%;" /></p>
<h2 id="training-a-multi-layered-perceptron">Training a multi-Layered perceptron</h2>
<p>In a multi-layer network, we will add one or more <strong>hidden layers</strong>.</p>
<p><img src="dense-multilayer-network.png" alt="dense-multilayer-network" style="zoom:25%;" /></p>
<p>A number of parameters of a neural network should be chosen depending on the dataset size, to prevent <strong>overfitting</strong>.</p>
<p>there is the non-linear activation function layer, called <strong>ReLU</strong>. if a network consisted just of a series of linear layers, it would essentially be equivalent to one linear layer.</p>
<p><img src="6.png" alt="multilayer-network-layers" style="zoom:50%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">relu_fn = torch.relu</span><br><span class="line">sigmoid_fn = torch.sigmoid</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;ReLU&quot;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(-<span class="number">10</span>,<span class="number">10</span>), [relu_fn(torch.tensor(x, dtype=torch.<span class="built_in">float</span>)).item() <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">10</span>, <span class="number">10</span>)])</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Sigmoid&quot;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(-<span class="number">10</span>,<span class="number">10</span>), [sigmoid_fn(torch.tensor(x, dtype=torch.<span class="built_in">float</span>)).item() <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">10</span>, <span class="number">10</span>)])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h3 id="network-definition">Network Definition</h3>
<blockquote>
<p>network layer structure:</p>
</blockquote>
<p><img src="multilayer-network-layers.png" alt="multilayer-network-layers" style="zoom:25%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(in_features=<span class="number">28</span> * <span class="number">28</span>, out_features=<span class="number">100</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(in_features=<span class="number">100</span>, out_features=<span class="number">10</span>),</span><br><span class="line">    nn.LogSoftmax(dim=<span class="number">0</span>)</span><br><span class="line">)</span><br><span class="line">summary(net, input_size=(<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line"></span><br><span class="line">==========================================================================================</span><br><span class="line">Layer (<span class="built_in">type</span>:depth-idx)                   Output Shape              Param <span class="comment">#</span></span><br><span class="line">==========================================================================================</span><br><span class="line">Model                                    --                        --</span><br><span class="line">├─Sequential: <span class="number">1</span>-<span class="number">1</span>                        [<span class="number">1</span>, <span class="number">10</span>]                   --</span><br><span class="line">│    └─Flatten: <span class="number">2</span>-<span class="number">1</span>                      [<span class="number">1</span>, <span class="number">784</span>]                  --</span><br><span class="line">│    └─Linear: <span class="number">2</span>-<span class="number">2</span>                       [<span class="number">1</span>, <span class="number">100</span>]                  <span class="number">78</span>,<span class="number">500</span></span><br><span class="line">│    └─ReLU: <span class="number">2</span>-<span class="number">3</span>                         [<span class="number">1</span>, <span class="number">100</span>]                  --</span><br><span class="line">│    └─Linear: <span class="number">2</span>-<span class="number">4</span>                       [<span class="number">1</span>, <span class="number">10</span>]                   <span class="number">1</span>,010</span><br><span class="line">│    └─LogSoftmax: <span class="number">2</span>-<span class="number">5</span>                   [<span class="number">1</span>, <span class="number">10</span>]                   --</span><br><span class="line">==========================================================================================</span><br><span class="line">Total params: <span class="number">79</span>,<span class="number">510</span></span><br><span class="line">Trainable params: <span class="number">79</span>,<span class="number">510</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">Total mult-adds (M): <span class="number">0.08</span></span><br><span class="line">==========================================================================================</span><br><span class="line">Input size (MB): <span class="number">0.00</span></span><br><span class="line">Forward/backward <span class="keyword">pass</span> size (MB): <span class="number">0.00</span></span><br><span class="line">Params size (MB): <span class="number">0.32</span></span><br><span class="line">Estimated Total Size (MB): <span class="number">0.32</span></span><br><span class="line">==========================================================================================</span><br></pre></td></tr></table></figure>
<p><img src="7.png" alt="7" style="zoom:50%;" /></p>
<ul>
<li>This network is more expressive than the one layered perceptron we have trained in the previous unit. Thus it achieves a much higher training accuracy and given sufficiently large number of parameters - it can get to almost 100%</li>
<li>Once the validation accuracy stops increasing - it means that the model has reached it's ability to generalize, and further training will likely to result in overfitting.</li>
</ul>
<h3 id="class-based-network-definitions">Class-based network definitions</h3>
<p>Defining models using a <code>Sequential</code> style as a list of layers seems very convenient but it is somewhat limited. At some point you may need to define more complex networks, which contain shared weights, or some non-linear connections between layers.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassBasedNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ClassBasedNet, self).__init__()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.hidden = nn.Linear(in_features=<span class="number">28</span> * <span class="number">28</span>, out_features=<span class="number">100</span>)</span><br><span class="line">        self.out = nn.Linear(in_features=<span class="number">100</span>, out_features=<span class="number">10</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.log_softmax = nn.LogSoftmax(dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.hidden(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.out(x)</span><br><span class="line">        x = self.log_softmax(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">     </span><br><span class="line">    </span><br><span class="line">==========================================================================================</span><br><span class="line">Layer (<span class="built_in">type</span>:depth-idx)                   Output Shape              Param <span class="comment">#</span></span><br><span class="line">==========================================================================================</span><br><span class="line">ClassBasedNet                            --                        --</span><br><span class="line">├─Flatten: <span class="number">1</span>-<span class="number">1</span>                           [<span class="number">1</span>, <span class="number">784</span>]                  --</span><br><span class="line">├─Linear: <span class="number">1</span>-<span class="number">2</span>                            [<span class="number">1</span>, <span class="number">100</span>]                  <span class="number">78</span>,<span class="number">500</span></span><br><span class="line">├─ReLU: <span class="number">1</span>-<span class="number">3</span>                              [<span class="number">1</span>, <span class="number">100</span>]                  --</span><br><span class="line">├─Linear: <span class="number">1</span>-<span class="number">4</span>                            [<span class="number">1</span>, <span class="number">10</span>]                   <span class="number">1</span>,010</span><br><span class="line">├─LogSoftmax: <span class="number">1</span>-<span class="number">5</span>                        [<span class="number">1</span>, <span class="number">10</span>]                   --</span><br><span class="line">==========================================================================================</span><br><span class="line">Total params: <span class="number">79</span>,<span class="number">510</span></span><br><span class="line">Trainable params: <span class="number">79</span>,<span class="number">510</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">Total mult-adds (M): <span class="number">0.08</span></span><br><span class="line">==========================================================================================</span><br><span class="line">Input size (MB): <span class="number">0.00</span></span><br><span class="line">Forward/backward <span class="keyword">pass</span> size (MB): <span class="number">0.00</span></span><br><span class="line">Params size (MB): <span class="number">0.32</span></span><br><span class="line">Estimated Total Size (MB): <span class="number">0.32</span></span><br><span class="line">==========================================================================================</span><br></pre></td></tr></table></figure>
<blockquote>
<p>自定义神经网络由一个继承自 <code>torch.nn.Module</code> 类的类来表示。类的定义包括两部分：</p>
<ul>
<li>在构造函数（<strong>init</strong>）中，我们定义了我们的网络将拥有的所有层。这些层被存储为类的内部变量，PyTorch自动优化这些层的参数。在内部，PyTorch使用<code>parameters()</code>方法来寻找所有可训练的参数，nn.Module自动从所有子模块中收集所有可训练的参数。</li>
<li>定义了<code>forward method</code>，对神经网络进行正向传递计算。在案例中，我们从一个参数 <code>tensor x</code>开始，明确地通过所有的层和激活函数，从<code>flatten</code>开始，直到最后的线性层<code>out</code>。当我们通过写<code>out = net(x)</code>将我们的神经网络应用于一些输入数据<code>x</code>时，前向方法被调用。</li>
</ul>
</blockquote>
<h2 id="convolutional-neural-network">convolutional neural network</h2>
<p>we will learn about <strong>Convolutional Neural Networks (CNNs)</strong>, which are specifically designed for computer vision.计算机视觉不同于一般的分类，因为当我们试图在图片中找到某个物体时，我们是在扫描图片，寻找一些特定的模式和它们的组合。例如，在寻找一只猫时，我们首先可能会寻找水平线，这可以形成胡须，然后胡须的某些组合可以告诉我们，这实际上是一张猫的照片。某些图案的相对位置和存在是重要的，而不是它们在图像上的确切位置。</p>
<h3 id="convolutional-filters">Convolutional filters</h3>
<blockquote>
<p>Convolutional filters are small windows that run over each pixel of the image and compute weighted average of the neighboring pixels.They are defined by matrices of weight coefficients. Let's see the examples of applying two different convolutional filters over our MNIST handwritten digits:</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_convolution</span>(<span class="params">training_data, kernel, title=<span class="string">&quot;&quot;</span></span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        c = nn.Conv2d(kernel_size=kernel.size(), out_channels=<span class="number">1</span>, in_channels=<span class="number">1</span>)</span><br><span class="line">        c.weight.copy_(kernel)</span><br><span class="line">        fig, ax = plt.subplots(<span class="number">2</span>, <span class="number">6</span>, figsize=(<span class="number">8</span>, <span class="number">3</span>))</span><br><span class="line">        fig.suptitle(title, fontsize=<span class="number">16</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            <span class="comment"># [1,28,28]</span></span><br><span class="line">            img = training_data[i][<span class="number">0</span>]</span><br><span class="line">            ax[<span class="number">0</span>][i].imshow(img[<span class="number">0</span>])</span><br><span class="line">            ax[<span class="number">0</span>][i].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">            <span class="comment"># [26, 26]</span></span><br><span class="line">            ax[<span class="number">1</span>][i].imshow(c(img.unsqueeze(<span class="number">0</span>))[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">            ax[<span class="number">1</span>][i].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        ax[<span class="number">0</span>, <span class="number">5</span>].imshow(kernel)</span><br><span class="line">        ax[<span class="number">0</span>, <span class="number">5</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        ax[<span class="number">1</span>, <span class="number">5</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    load_mnist()</span><br><span class="line">    Vertical_edge_filter = torch.tensor([[-<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">1.</span>], [-<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">1.</span>], [-<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">1.</span>]])</span><br><span class="line">    Horizontal_edge_filter = torch.tensor([[-<span class="number">1.</span>,-<span class="number">1.</span>,-<span class="number">1.</span>],[<span class="number">0.</span>,<span class="number">0.</span>,<span class="number">0.</span>],[<span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span>]])</span><br><span class="line">    plot_convolution(training_data, Vertical_edge_filter, <span class="string">&quot;Vertical edge filter&quot;</span>)</span><br><span class="line">    plot_convolution(training_data, Horizontal_edge_filter, <span class="string">&quot;Horizontal edge filter&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="8.png" alt="8" style="zoom:50%;" /></p>
<p><img src="9.png" alt="9" style="zoom:50%;" /></p>
<p><strong>vertical edge filter</strong>: $$ (</p>
​
<span class="math display">\[\begin{matrix}

​     -1 &amp; 0 &amp; 1 \\

​     -1 &amp; 0 &amp; 1 \\

​     -1 &amp; 0 &amp; 1 

​    \end{matrix}\]</span>
<p>) $$</p>
<h3 id="covolutional-layers">Covolutional layers</h3>
<blockquote>
<p>Convolutional layers are defined using <code>nn.Conv2d</code> construction:</p>
<ul>
<li><code>in_channels</code> - number of input channels. In our case we are dealing with a grayscale image, thus number of input channels is 1.</li>
<li><code>out_channels</code> - number of filters to use. We will use 9 different filters, which will give the network plenty of opportunities to explore which filters work best for our scenario.</li>
<li><code>kernel_size</code> is the size of the sliding window. Usually 3x3 or 5x5 filters are used.</li>
</ul>
</blockquote>
<p>Simplest CNN contains one convolutional layer.</p>
<ul>
<li><p>Given the input size 28x28, applying nine 5x5 filters</p></li>
<li><p>end up with a tensor of 9x24x24 (there are only 24 positions where a sliding interval of length 5 can fit into 28 pixels).</p></li>
<li><p>flatten 9x24x24 tensor into one vector of size 5184, and then add linear layer, to produce 10 classes. (use <code>relu</code> activation function in between layers.)</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimplestConv</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SimplestConv, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(kernel_size=(<span class="number">5</span>,<span class="number">5</span>), in_channels=<span class="number">1</span>, out_channels=<span class="number">9</span>)</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.linear = nn.Linear(in_features=<span class="number">9</span>*<span class="number">24</span>*<span class="number">24</span>, out_features=<span class="number">10</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.log_softmax = nn.LogSoftmax(dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.linear(x)</span><br><span class="line">        x = self.log_softmax(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">      </span><br><span class="line">==========================================================================================</span><br><span class="line">Layer (<span class="built_in">type</span>:depth-idx)                   Output Shape              Param <span class="comment">#</span></span><br><span class="line">==========================================================================================</span><br><span class="line">SimplestConv                             --                        --</span><br><span class="line">├─Conv2d: <span class="number">1</span>-<span class="number">1</span>                            [<span class="number">1</span>, <span class="number">9</span>, <span class="number">24</span>, <span class="number">24</span>]            <span class="number">234</span></span><br><span class="line">├─ReLU: <span class="number">1</span>-<span class="number">2</span>                              [<span class="number">1</span>, <span class="number">9</span>, <span class="number">24</span>, <span class="number">24</span>]            --</span><br><span class="line">├─Flatten: <span class="number">1</span>-<span class="number">3</span>                           [<span class="number">1</span>, <span class="number">5184</span>]                 --</span><br><span class="line">├─Linear: <span class="number">1</span>-<span class="number">4</span>                            [<span class="number">1</span>, <span class="number">10</span>]                   <span class="number">51</span>,<span class="number">850</span></span><br><span class="line">├─LogSoftmax: <span class="number">1</span>-<span class="number">5</span>                        [<span class="number">1</span>, <span class="number">10</span>]                   --</span><br><span class="line">==========================================================================================</span><br><span class="line">Total params: <span class="number">52</span>,084</span><br><span class="line">Trainable params: <span class="number">52</span>,084</span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">Total mult-adds (M): <span class="number">0.19</span></span><br><span class="line">==========================================================================================</span><br><span class="line">Input size (MB): <span class="number">0.00</span></span><br><span class="line">Forward/backward <span class="keyword">pass</span> size (MB): <span class="number">0.04</span></span><br><span class="line">Params size (MB): <span class="number">0.21</span></span><br><span class="line">Estimated Total Size (MB): <span class="number">0.25</span></span><br><span class="line">==========================================================================================</span><br><span class="line"></span><br><span class="line">epoch: <span class="number">1</span></span><br><span class="line">---------------------------------</span><br><span class="line">loss: <span class="number">4.846857</span>    [<span class="number">0</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.922879</span>    [<span class="number">12800</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.829096</span>    [<span class="number">25600</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.816400</span>    [<span class="number">38400</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.833445</span>    [<span class="number">51200</span>/<span class="number">60000</span>]</span><br><span class="line">train_loss: <span class="number">2.916213</span>   train_acc: <span class="number">0.952633</span></span><br><span class="line">val_loss: <span class="number">2.824616</span>  val_acc: <span class="number">0.972700</span> </span><br><span class="line"> </span><br><span class="line">epoch: <span class="number">2</span></span><br><span class="line">---------------------------------</span><br><span class="line">loss: <span class="number">2.841105</span>    [<span class="number">0</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.804442</span>    [<span class="number">12800</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.739106</span>    [<span class="number">25600</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.762817</span>    [<span class="number">38400</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.776352</span>    [<span class="number">51200</span>/<span class="number">60000</span>]</span><br><span class="line">train_loss: <span class="number">2.796383</span>   train_acc: <span class="number">0.976933</span></span><br><span class="line">val_loss: <span class="number">2.808884</span>  val_acc: <span class="number">0.975700</span> </span><br><span class="line"> </span><br><span class="line">epoch: <span class="number">3</span></span><br><span class="line">---------------------------------</span><br><span class="line">loss: <span class="number">2.801105</span>    [<span class="number">0</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.779864</span>    [<span class="number">12800</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.730634</span>    [<span class="number">25600</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.752127</span>    [<span class="number">38400</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.773396</span>    [<span class="number">51200</span>/<span class="number">60000</span>]</span><br><span class="line">train_loss: <span class="number">2.775327</span>   train_acc: <span class="number">0.979883</span></span><br><span class="line">val_loss: <span class="number">2.806651</span>  val_acc: <span class="number">0.974600</span> </span><br><span class="line"> </span><br><span class="line">epoch: <span class="number">4</span></span><br><span class="line">---------------------------------</span><br><span class="line">loss: <span class="number">2.797673</span>    [<span class="number">0</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.769010</span>    [<span class="number">12800</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.745473</span>    [<span class="number">25600</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.741996</span>    [<span class="number">38400</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.784167</span>    [<span class="number">51200</span>/<span class="number">60000</span>]</span><br><span class="line">train_loss: <span class="number">2.764126</span>   train_acc: <span class="number">0.981950</span></span><br><span class="line">val_loss: <span class="number">2.808089</span>  val_acc: <span class="number">0.973000</span> </span><br><span class="line"> </span><br><span class="line">epoch: <span class="number">5</span></span><br><span class="line">---------------------------------</span><br><span class="line">loss: <span class="number">2.784624</span>    [<span class="number">0</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.738271</span>    [<span class="number">12800</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.741519</span>    [<span class="number">25600</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.739913</span>    [<span class="number">38400</span>/<span class="number">60000</span>]</span><br><span class="line">loss: <span class="number">2.778515</span>    [<span class="number">51200</span>/<span class="number">60000</span>]</span><br><span class="line">train_loss: <span class="number">2.755174</span>   train_acc: <span class="number">0.982967</span></span><br><span class="line">val_loss: <span class="number">2.819919</span>  val_acc: <span class="number">0.971700</span> </span><br></pre></td></tr></table></figure>
<p><img src="10.png" alt="10" style="zoom:50%;" /></p>
<p>visualize the weights of our trained convolutional layers, to try and make some more sense of what is going on:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">  weight_tensor = <span class="built_in">next</span>(self.model.parameters())</span><br><span class="line">  fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">9</span>, figsize=(<span class="number">10</span>,<span class="number">3</span>))</span><br><span class="line">  <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(weight_tensor):</span><br><span class="line">      ax[i].imshow(x.detach().cpu().squeeze(dim=<span class="number">0</span>))</span><br><span class="line">      ax[i].axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">      plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="11.png" alt="11" style="zoom:60%;" /></p>
<h2 id="multi-layered-cnns-and-pooling-layers">Multi-layered CNNs and pooling layers</h2>
<p>reducing the spatial size of the image："scale down" the size of the image, which is done using one of the <strong>pooling layers</strong>:</p>
<ul>
<li><strong>Average Pooling</strong> takes a sliding window (for example, 2x2 pixels) and computes an average of values within the window</li>
<li><strong>Max Pooling</strong> replaces the window with the maximum value. The idea behind max pooling is to detect a presence of a certain pattern within the sliding window.</li>
</ul>
<p>in a typical CNN there would be several convolutional layers, with pooling layers in between them to decrease dimensions of the image. We would also increase the number of filters, because as patterns become more advanced - there are more possible interesting combinations that we need to be looking for.</p>
<p><img src="cnn-pyramid.png" alt="cnn-pyramid" style="zoom:50%;" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiLayerCNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MultiLayerCNN, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">10</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">        self.maxPool = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">10</span>, out_channels=<span class="number">20</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">        self.linear = nn.Linear(in_features=<span class="number">20</span>*<span class="number">4</span>*<span class="number">4</span>, out_features=<span class="number">10</span>)</span><br><span class="line">        self.logSoftmax = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxPool(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxPool(x)</span><br><span class="line"></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> self.logSoftmax(x)</span><br><span class="line">      </span><br><span class="line">==========================================================================================</span><br><span class="line">Layer (<span class="built_in">type</span>:depth-idx)                   Output Shape              Param <span class="comment">#</span></span><br><span class="line">==========================================================================================</span><br><span class="line">MultiLayerCNN                            --                        --</span><br><span class="line">├─Conv2d: <span class="number">1</span>-<span class="number">1</span>                            [<span class="number">1</span>, <span class="number">10</span>, <span class="number">24</span>, <span class="number">24</span>]           <span class="number">260</span></span><br><span class="line">├─ReLU: <span class="number">1</span>-<span class="number">2</span>                              [<span class="number">1</span>, <span class="number">10</span>, <span class="number">24</span>, <span class="number">24</span>]           --</span><br><span class="line">├─MaxPool2d: <span class="number">1</span>-<span class="number">3</span>                         [<span class="number">1</span>, <span class="number">10</span>, <span class="number">12</span>, <span class="number">12</span>]           --</span><br><span class="line">├─Conv2d: <span class="number">1</span>-<span class="number">4</span>                            [<span class="number">1</span>, <span class="number">20</span>, <span class="number">8</span>, <span class="number">8</span>]             <span class="number">5</span>,020</span><br><span class="line">├─ReLU: <span class="number">1</span>-<span class="number">5</span>                              [<span class="number">1</span>, <span class="number">20</span>, <span class="number">8</span>, <span class="number">8</span>]             --</span><br><span class="line">├─MaxPool2d: <span class="number">1</span>-<span class="number">6</span>                         [<span class="number">1</span>, <span class="number">20</span>, <span class="number">4</span>, <span class="number">4</span>]             --</span><br><span class="line">├─Flatten: <span class="number">1</span>-<span class="number">7</span>                           [<span class="number">1</span>, <span class="number">320</span>]                  --</span><br><span class="line">├─Linear: <span class="number">1</span>-<span class="number">8</span>                            [<span class="number">1</span>, <span class="number">10</span>]                   <span class="number">3</span>,<span class="number">210</span></span><br><span class="line">├─LogSoftmax: <span class="number">1</span>-<span class="number">9</span>                        [<span class="number">1</span>, <span class="number">10</span>]                   --</span><br><span class="line">==========================================================================================</span><br><span class="line">Total params: <span class="number">8</span>,<span class="number">490</span></span><br><span class="line">Trainable params: <span class="number">8</span>,<span class="number">490</span></span><br><span class="line">Non-trainable params: <span class="number">0</span></span><br><span class="line">Total mult-adds (M): <span class="number">0.47</span></span><br><span class="line">==========================================================================================</span><br></pre></td></tr></table></figure>
<p><img src="12.png" alt="12" style="zoom:50%;" /></p>
<h2 id="playing-with-real-images-from-the-cifar-10-dataset">Playing with real images from the CIFAR-10 dataset</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_dataset</span>(<span class="params">dataset</span>):</span></span><br><span class="line">    cols, rows = <span class="number">2</span>, <span class="number">8</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">    n = <span class="built_in">len</span>(dataset.classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, rows * cols + <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">id</span> = torch.randint(<span class="built_in">len</span>(dataset), size=(<span class="number">1</span>,)).item()</span><br><span class="line">        mn = <span class="built_in">min</span>([dataset[<span class="built_in">id</span>][<span class="number">0</span>].<span class="built_in">min</span>() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)])</span><br><span class="line">        mx = <span class="built_in">max</span>([dataset[<span class="built_in">id</span>][<span class="number">0</span>].<span class="built_in">max</span>() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)])</span><br><span class="line">        x, y = dataset[<span class="built_in">id</span>]</span><br><span class="line">        x = np.transpose((x-mn)/(mx-mn), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">        plt.subplot(cols, rows, i)</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        plt.title(dataset.classes[y])</span><br><span class="line">        plt.imshow(x)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="13.png" alt="13" style="zoom:60%;" /></p>
<blockquote>
<p>A well-known architecture for CIFAR-10 is called <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/LeNet">LeNet</a>, and has been proposed by <em>Yann LeCun</em>. It follows the same principles as we have outlined above, the main difference being 3 input color channels instead of 1.</p>
<p>We also do one more simplification to this model - we do not use <code>log_softmax</code> as output activation function, and just return the output of last fully-connected layer. In this case we can just use <code>CrossEntropyLoss</code> loss function to optimize the model.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">6</span>, kernel_size=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">6</span>, out_channels=<span class="number">16</span>, kernel_size=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.conv3 = nn.Conv2d(in_channels=<span class="number">16</span>, out_channels=<span class="number">120</span>, kernel_size=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">        self.maxPool = nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line">        self.linear1 = nn.Linear(in_features=<span class="number">120</span>, out_features=<span class="number">64</span>)</span><br><span class="line">        self.linear2 = nn.Linear(in_features=<span class="number">64</span>, out_features=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.maxPool(self.relu(self.conv1(x)))</span><br><span class="line">        x = self.maxPool(self.relu(self.conv2(x)))</span><br><span class="line">        x = self.relu(self.conv3(x))</span><br><span class="line"></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.linear1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        <span class="keyword">return</span> self.linear2(x)</span><br><span class="line">      </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    DataSet.load_cifar_10()</span><br><span class="line">    model = LeNet()</span><br><span class="line">    summary(model, input_size=(<span class="number">1</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">32</span>))</span><br><span class="line">    </span><br><span class="line">==========================================================================================</span><br><span class="line">Layer (<span class="built_in">type</span>:depth-idx)                   Output Shape              Param <span class="comment">#</span></span><br><span class="line">==========================================================================================</span><br><span class="line">LeNet                                    --                        --</span><br><span class="line">├─Conv2d: <span class="number">1</span>-<span class="number">1</span>                            [<span class="number">1</span>, <span class="number">6</span>, <span class="number">28</span>, <span class="number">28</span>]            <span class="number">456</span></span><br><span class="line">├─ReLU: <span class="number">1</span>-<span class="number">2</span>                              [<span class="number">1</span>, <span class="number">6</span>, <span class="number">28</span>, <span class="number">28</span>]            --</span><br><span class="line">├─MaxPool2d: <span class="number">1</span>-<span class="number">3</span>                         [<span class="number">1</span>, <span class="number">6</span>, <span class="number">14</span>, <span class="number">14</span>]            --</span><br><span class="line">├─Conv2d: <span class="number">1</span>-<span class="number">4</span>                            [<span class="number">1</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>]           <span class="number">2</span>,<span class="number">416</span></span><br><span class="line">├─ReLU: <span class="number">1</span>-<span class="number">5</span>                              [<span class="number">1</span>, <span class="number">16</span>, <span class="number">10</span>, <span class="number">10</span>]           --</span><br><span class="line">├─MaxPool2d: <span class="number">1</span>-<span class="number">6</span>                         [<span class="number">1</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>]             --</span><br><span class="line">├─Conv2d: <span class="number">1</span>-<span class="number">7</span>                            [<span class="number">1</span>, <span class="number">120</span>, <span class="number">1</span>, <span class="number">1</span>]            <span class="number">48</span>,<span class="number">120</span></span><br><span class="line">├─ReLU: <span class="number">1</span>-<span class="number">8</span>                              [<span class="number">1</span>, <span class="number">120</span>, <span class="number">1</span>, <span class="number">1</span>]            --</span><br><span class="line">├─Flatten: <span class="number">1</span>-<span class="number">9</span>                           [<span class="number">1</span>, <span class="number">120</span>]                  --</span><br><span class="line">├─Linear: <span class="number">1</span>-<span class="number">10</span>                           [<span class="number">1</span>, <span class="number">64</span>]                   <span class="number">7</span>,<span class="number">744</span></span><br><span class="line">├─ReLU: <span class="number">1</span>-<span class="number">11</span>                             [<span class="number">1</span>, <span class="number">64</span>]                   --</span><br><span class="line">├─Linear: <span class="number">1</span>-<span class="number">12</span>                           [<span class="number">1</span>, <span class="number">10</span>]                   <span class="number">650</span></span><br><span class="line">==========================================================================================</span><br></pre></td></tr></table></figure>
<p><img src="14.png" alt="13" style="zoom:60%;" /></p>
<h3 id="pre-trained-models-and-transfer-learning">Pre-trained models and transfer learning</h3>
<p>训练CNN可能需要很多时间，而且这项任务需要大量的数据。然而，大部分时间是用来学习网络用来从图像中提取模式的<code>best low-level filters</code>。</p>
<p><code>转移学习</code>，将一些知识从一个神经网络模型转移到另一个。在迁移学习中，我们通常从一个预先训练好的模型开始，这个模型已经在一些大型图像数据集上训练过了，比如ImageNet。这些模型已经可以很好地从通用图像中提取不同的特征，在很多情况下，只要在这些提取的特征之上建立一个分类器就可以产生一个好的结果。</p>
<h2 id="playing-with-cats-vs.-dogs-dataset">Playing with Cats vs. Dogs Dataset</h2>
<blockquote>
<p>solving a real-life problem of classifying images of cats and dogs. we will use <a target="_blank" rel="noopener" href="https://www.kaggle.com/c/dogs-vs-cats">Kaggle Cats vs. Dogs Dataset</a>, which can also be downloaded <a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/download/details.aspx?id=54765">from Microsoft</a>.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">data_url = <span class="string">&quot;https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip&quot;</span></span><br><span class="line">data_path = <span class="string">&#x27;data/kagglecatsanddogs_3367a.zip&#x27;</span></span><br><span class="line">data_dir = <span class="string">&#x27;data/PetImages&#x27;</span></span><br><span class="line">frame_name = <span class="string">&#x27;kagglecatsanddogs_3367a.zip&#x27;</span></span><br><span class="line">root = <span class="string">&#x27;data&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span>():</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(data_path):</span><br><span class="line">        wget.download(data_url, data_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(data_dir):</span><br><span class="line">        <span class="keyword">with</span> zipfile.ZipFile(data_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> zip_ref:</span><br><span class="line">            zip_ref.extractall(root)</span><br><span class="line">    check_image_dir(data_dir + <span class="string">&#x27;/Cat/*.jpg&#x27;</span>)</span><br><span class="line">    check_image_dir(data_dir + <span class="string">&#x27;/Dog/*.jpg&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_image</span>(<span class="params">fn</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        im = Image.<span class="built_in">open</span>(fn)</span><br><span class="line">        im.verify()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_image_dir</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">for</span> fn <span class="keyword">in</span> glob.glob(path):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> check_image(fn):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Corrupt image: <span class="subst">&#123;fn&#125;</span>&quot;</span>)</span><br><span class="line">            os.remove(fn)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>load the images into PyTorch dataset, converting them to tensors and doing some normalization. We will apply <code>std_normalize</code> transform to bring images to the range expected by pre-trained VGG network:</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">std_normalize = torchvision.transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">transform = torchvision.transform.Compose(</span><br><span class="line">		[</span><br><span class="line">      	torchvision.transforms.Resize(<span class="number">256</span>),</span><br><span class="line">      	torchvision.transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">      	torchvision.transforms.ToTensor(),</span><br><span class="line">      	std_normalize</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">dataset = torchvision.datasets.ImageFolder(data_dir, transform=transform)</span><br><span class="line">training_data, test_data = torch.utils.data.random_split(dataset, [<span class="number">20000</span>, <span class="built_in">len</span>(dataset)-<span class="number">20000</span>])</span><br><span class="line">training_dataloader = torch.utils.data.DataLoader(training_data, bach_size)</span><br><span class="line">test_dataloader = torch.utils.data.DataLoader(test_data, bach_size)</span><br><span class="line"></span><br><span class="line">plot_dataset(dataset, dataset.classes)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_dataset</span>(<span class="params">dataset, classes</span>):</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">    cols, rows = <span class="number">2</span>, <span class="number">8</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, cols * rows + <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">id</span> = torch.randint(<span class="built_in">len</span>(dataset), size=(<span class="number">1</span>,)).item()</span><br><span class="line">        x, y = dataset[<span class="built_in">id</span>]</span><br><span class="line">        mn = <span class="built_in">min</span>([dataset[<span class="built_in">id</span>][<span class="number">0</span>].<span class="built_in">min</span>() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes))])</span><br><span class="line">        mx = <span class="built_in">max</span>([dataset[<span class="built_in">id</span>][<span class="number">0</span>].<span class="built_in">max</span>() <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes))])</span><br><span class="line">        x = transpose((x - mn) / (mx - mn), (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        plt.subplot(cols, rows, i)</span><br><span class="line">        plt.title(classes[y])</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        plt.imshow(x)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="15.png" alt="15" style="zoom:60%;" /></p>
<h3 id="pre-trained-models">pre-trained models</h3>
<p>There are many different pre-trained models available inside <code>torchvision</code> module, and even more models can be found on the Internet. Let's see how simplest VGG-16 model can be loaded and used:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">vgg = torchvision.models.vgg16(pretrained=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">==========================================================================================</span><br><span class="line">Layer (type:depth-idx)                   Output Shape              Param #</span><br><span class="line">==========================================================================================</span><br><span class="line">Vgg16                                    --                        --</span><br><span class="line">├─VGG: 1-1                               [1, 1000]                 --</span><br><span class="line">│    └─Sequential: 2-1                   [1, 512, 7, 7]            --</span><br><span class="line">│    │    └─Conv2d: 3-1                  [1, 64, 224, 224]         1,792</span><br><span class="line">│    │    └─ReLU: 3-2                    [1, 64, 224, 224]         --</span><br><span class="line">│    │    └─Conv2d: 3-3                  [1, 64, 224, 224]         36,928</span><br><span class="line">│    │    └─ReLU: 3-4                    [1, 64, 224, 224]         --</span><br><span class="line">│    │    └─MaxPool2d: 3-5               [1, 64, 112, 112]         --</span><br><span class="line">│    │    └─Conv2d: 3-6                  [1, 128, 112, 112]        73,856</span><br><span class="line">│    │    └─ReLU: 3-7                    [1, 128, 112, 112]        --</span><br><span class="line">│    │    └─Conv2d: 3-8                  [1, 128, 112, 112]        147,584</span><br><span class="line">│    │    └─ReLU: 3-9                    [1, 128, 112, 112]        --</span><br><span class="line">│    │    └─MaxPool2d: 3-10              [1, 128, 56, 56]          --</span><br><span class="line">│    │    └─Conv2d: 3-11                 [1, 256, 56, 56]          295,168</span><br><span class="line">│    │    └─ReLU: 3-12                   [1, 256, 56, 56]          --</span><br><span class="line">│    │    └─Conv2d: 3-13                 [1, 256, 56, 56]          590,080</span><br><span class="line">│    │    └─ReLU: 3-14                   [1, 256, 56, 56]          --</span><br><span class="line">│    │    └─Conv2d: 3-15                 [1, 256, 56, 56]          590,080</span><br><span class="line">│    │    └─ReLU: 3-16                   [1, 256, 56, 56]          --</span><br><span class="line">│    │    └─MaxPool2d: 3-17              [1, 256, 28, 28]          --</span><br><span class="line">│    │    └─Conv2d: 3-18                 [1, 512, 28, 28]          1,180,160</span><br><span class="line">│    │    └─ReLU: 3-19                   [1, 512, 28, 28]          --</span><br><span class="line">│    │    └─Conv2d: 3-20                 [1, 512, 28, 28]          2,359,808</span><br><span class="line">│    │    └─ReLU: 3-21                   [1, 512, 28, 28]          --</span><br><span class="line">│    │    └─Conv2d: 3-22                 [1, 512, 28, 28]          2,359,808</span><br><span class="line">│    │    └─ReLU: 3-23                   [1, 512, 28, 28]          --</span><br><span class="line">│    │    └─MaxPool2d: 3-24              [1, 512, 14, 14]          --</span><br><span class="line">│    │    └─Conv2d: 3-25                 [1, 512, 14, 14]          2,359,808</span><br><span class="line">│    │    └─ReLU: 3-26                   [1, 512, 14, 14]          --</span><br><span class="line">│    │    └─Conv2d: 3-27                 [1, 512, 14, 14]          2,359,808</span><br><span class="line">│    │    └─ReLU: 3-28                   [1, 512, 14, 14]          --</span><br><span class="line">│    │    └─Conv2d: 3-29                 [1, 512, 14, 14]          2,359,808</span><br><span class="line">│    │    └─ReLU: 3-30                   [1, 512, 14, 14]          --</span><br><span class="line">│    │    └─MaxPool2d: 3-31              [1, 512, 7, 7]            --</span><br><span class="line">│    └─AdaptiveAvgPool2d: 2-2            [1, 512, 7, 7]            --</span><br><span class="line">│    └─Sequential: 2-3                   [1, 1000]                 --</span><br><span class="line">│    │    └─Linear: 3-32                 [1, 4096]                 102,764,544</span><br><span class="line">│    │    └─ReLU: 3-33                   [1, 4096]                 --</span><br><span class="line">│    │    └─Dropout: 3-34                [1, 4096]                 --</span><br><span class="line">│    │    └─Linear: 3-35                 [1, 4096]                 16,781,312</span><br><span class="line">│    │    └─ReLU: 3-36                   [1, 4096]                 --</span><br><span class="line">│    │    └─Dropout: 3-37                [1, 4096]                 --</span><br><span class="line">│    │    └─Linear: 3-38                 [1, 1000]                 4,097,000</span><br><span class="line">==========================================================================================</span><br><span class="line">Total params: 138,357,544</span><br><span class="line">Trainable params: 138,357,544</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">Total mult-adds (G): 15.48</span><br><span class="line">==========================================================================================</span><br><span class="line">Input size (MB): 0.60</span><br><span class="line">Forward/backward pass size (MB): 108.45</span><br><span class="line">Params size (MB): 553.43</span><br><span class="line">Estimated Total Size (MB): 662.49</span><br><span class="line">==========================================================================================</span><br></pre></td></tr></table></figure>
<blockquote>
<p>DropOut: 正则化对学习算法做了轻微的修改，因此模型的泛化效果更好。在训练过程中，剔除层丢弃了前一层的某些比例（大约30%）的神经元，在没有它们的情况下进行训练。这有助于使优化过程脱离局部最小值，并在不同的神经路径之间分配决定性的力量，从而提高网络的整体稳定性。</p>
</blockquote>
<h3 id="extracting-vgg-features">Extracting VGG features</h3>
<p>If we want to use VGG-16 to extract features from our images, we need the model without final classification layers. In fact, this "feature extractor" can be obtained using <code>vgg.features</code> method:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res = vgg.features(sample_image).cpu()</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">plt.imshow(res.detach().view(-<span class="number">1</span>,<span class="number">512</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="16.png" alt="16" style="zoom:60%;" /></p>
<p>those features can be used to classify images. Let's manually take some portion of images (800 in our case), and pre-compute their feature vectors. store the result in one big tensor called <code>feature_tensor</code>, and also labels into <code>label_tensor</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">manual_feature_extraction</span>(<span class="params">training_dataloader</span>):</span></span><br><span class="line">    <span class="comment"># The dimension of feature tensor is 512x7x7,</span></span><br><span class="line">    num = batch_size * <span class="number">100</span></span><br><span class="line">    vgg = vgg16(pretrained=<span class="literal">True</span>).to(device)</span><br><span class="line">    feature_tensor = torch.zeros(num, <span class="number">512</span> * <span class="number">7</span> * <span class="number">7</span>).to(device)</span><br><span class="line">    label_tensor = torch.zeros(num).to(device)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(training_dataloader):</span><br><span class="line">            f = vgg.features(x.to(device))</span><br><span class="line">            feature_tensor[batch:batch + batch_size] = f.view(batch_size, -<span class="number">1</span>)</span><br><span class="line">            label_tensor[batch:batch + batch_size] = y</span><br><span class="line">            <span class="keyword">if</span> batch * batch_size &gt; num:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    vgg_dataset = TensorDataset(feature_tensor, label_tensor.to(torch.long))</span><br><span class="line">    size, train_size = <span class="built_in">len</span>(vgg_dataset), <span class="built_in">int</span>(<span class="built_in">len</span>(vgg_dataset) / <span class="number">7</span> * <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">    training_data, test_data = random_split(vgg_dataset, [train_size, size - train_size])</span><br><span class="line">    training_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> training_dataloader, test_dataloader</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    load_data()</span><br><span class="line">    net = nn.Sequential(nn.Linear(<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>, <span class="number">2</span>), nn.Softmax()).to(device)</span><br><span class="line">    train_feature_loader, test_feature_loader = manual_feature_extraction(training_dataloader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;features extraction done&quot;</span>)</span><br><span class="line">    hist = train(net, train_feature_loader, test_feature_loader)</span><br><span class="line">    displayutils.plot_acc_loss(hist)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">features extraction done</span><br><span class="line">epoch: <span class="number">1</span></span><br><span class="line">------------------------------------------</span><br><span class="line">train loss: <span class="number">0.6915339231491089</span>  [<span class="number">0</span>/<span class="number">2742</span>]</span><br><span class="line">train_loss: <span class="number">0.692696</span>     train_acc: <span class="number">0.920496</span>     <span class="number">2742</span></span><br><span class="line">val_loss: <span class="number">0.675718</span>     val_acc: <span class="number">0.989083</span>     <span class="number">458</span></span><br><span class="line">    </span><br><span class="line">epoch: <span class="number">2</span></span><br><span class="line">------------------------------------------</span><br><span class="line">train loss: <span class="number">0.6835835576057434</span>  [<span class="number">0</span>/<span class="number">2742</span>]</span><br><span class="line">train_loss: <span class="number">0.676036</span>     train_acc: <span class="number">0.998906</span>     <span class="number">2742</span></span><br><span class="line">val_loss: <span class="number">0.664526</span>     val_acc: <span class="number">0.993450</span>     <span class="number">458</span></span><br><span class="line">    </span><br><span class="line">epoch: <span class="number">3</span></span><br><span class="line">------------------------------------------</span><br><span class="line">train loss: <span class="number">0.6631014347076416</span>  [<span class="number">0</span>/<span class="number">2742</span>]</span><br><span class="line">train_loss: <span class="number">0.664522</span>     train_acc: <span class="number">0.999635</span>     <span class="number">2742</span></span><br><span class="line">val_loss: <span class="number">0.652398</span>     val_acc: <span class="number">0.993450</span>     <span class="number">458</span></span><br><span class="line">    </span><br><span class="line">epoch: <span class="number">4</span></span><br><span class="line">------------------------------------------</span><br><span class="line">train loss: <span class="number">0.6546106338500977</span>  [<span class="number">0</span>/<span class="number">2742</span>]</span><br><span class="line">train_loss: <span class="number">0.654346</span>     train_acc: <span class="number">1.000000</span>     <span class="number">2742</span></span><br><span class="line">val_loss: <span class="number">0.643583</span>     val_acc: <span class="number">0.993450</span>     <span class="number">458</span></span><br></pre></td></tr></table></figure>
<p><img src="17.png" alt="17" style="zoom:60%;" /></p>
<h3 id="transfer-learning-using-one-vgg-network">Transfer learning using one VGG network</h3>
<p>the VGG contains:</p>
<ul>
<li>feature extractor (<code>features</code>), comprised of a number of convolutional and pooling layers</li>
<li>average pooling layer (<code>avgpool</code>)</li>
<li>final <code>classifier</code>, consisting of several dense layers, which turns 25088 input features into 1000 classes (which is the number of classes in ImageNet)</li>
</ul>
<p>To train the end-to-end model that will classify our dataset, we need to:</p>
<ul>
<li><strong>replace the final classifier</strong> with the one that will produce required number of classes. In our case, we can use one <code>Linear</code> layer with 25088 inputs and 2 output neurons.</li>
<li><strong>freeze weights of convolutional feature extractor</strong>, so that they are not trained. It is recommended to initially do this freezing, because otherwise untrained classifier layer can destroy the original pre-trained weights of convolutional extractor. Freezing weights can be accomplished by setting <code>requires_grad</code> property of all parameters to <code>False</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TransferVgg16</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(TransferVgg16, self).__init__()</span><br><span class="line">        self.vgg16 = vgg16(pretrained=<span class="literal">True</span>).to(device)</span><br><span class="line">        self.vgg16.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(in_features=<span class="number">512</span> * <span class="number">7</span> * <span class="number">7</span>, out_features=<span class="number">2</span>),</span><br><span class="line">            nn.Softmax()</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self.vgg16.features.parameters():</span><br><span class="line">            x.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.vgg16(x)</span><br><span class="line">      </span><br><span class="line">==========================================================================================</span><br><span class="line">Layer (<span class="built_in">type</span>:depth-idx)                   Output Shape              Param <span class="comment">#</span></span><br><span class="line">==========================================================================================</span><br><span class="line">TransferVgg16                            --                        --</span><br><span class="line">├─VGG: <span class="number">1</span>-<span class="number">1</span>                               [<span class="number">1</span>, <span class="number">2</span>]                    --</span><br><span class="line">│    └─Sequential: <span class="number">2</span>-<span class="number">1</span>                   [<span class="number">1</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>]            --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">1</span>                  [<span class="number">1</span>, <span class="number">64</span>, <span class="number">244</span>, <span class="number">244</span>]         (<span class="number">1</span>,<span class="number">792</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">2</span>                    [<span class="number">1</span>, <span class="number">64</span>, <span class="number">244</span>, <span class="number">244</span>]         --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">3</span>                  [<span class="number">1</span>, <span class="number">64</span>, <span class="number">244</span>, <span class="number">244</span>]         (<span class="number">36</span>,<span class="number">928</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">4</span>                    [<span class="number">1</span>, <span class="number">64</span>, <span class="number">244</span>, <span class="number">244</span>]         --</span><br><span class="line">│    │    └─MaxPool2d: <span class="number">3</span>-<span class="number">5</span>               [<span class="number">1</span>, <span class="number">64</span>, <span class="number">122</span>, <span class="number">122</span>]         --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">6</span>                  [<span class="number">1</span>, <span class="number">128</span>, <span class="number">122</span>, <span class="number">122</span>]        (<span class="number">73</span>,<span class="number">856</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">7</span>                    [<span class="number">1</span>, <span class="number">128</span>, <span class="number">122</span>, <span class="number">122</span>]        --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">8</span>                  [<span class="number">1</span>, <span class="number">128</span>, <span class="number">122</span>, <span class="number">122</span>]        (<span class="number">147</span>,<span class="number">584</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">9</span>                    [<span class="number">1</span>, <span class="number">128</span>, <span class="number">122</span>, <span class="number">122</span>]        --</span><br><span class="line">│    │    └─MaxPool2d: <span class="number">3</span>-<span class="number">10</span>              [<span class="number">1</span>, <span class="number">128</span>, <span class="number">61</span>, <span class="number">61</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">11</span>                 [<span class="number">1</span>, <span class="number">256</span>, <span class="number">61</span>, <span class="number">61</span>]          (<span class="number">295</span>,<span class="number">168</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">12</span>                   [<span class="number">1</span>, <span class="number">256</span>, <span class="number">61</span>, <span class="number">61</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">13</span>                 [<span class="number">1</span>, <span class="number">256</span>, <span class="number">61</span>, <span class="number">61</span>]          (<span class="number">590</span>,080)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">14</span>                   [<span class="number">1</span>, <span class="number">256</span>, <span class="number">61</span>, <span class="number">61</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">15</span>                 [<span class="number">1</span>, <span class="number">256</span>, <span class="number">61</span>, <span class="number">61</span>]          (<span class="number">590</span>,080)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">16</span>                   [<span class="number">1</span>, <span class="number">256</span>, <span class="number">61</span>, <span class="number">61</span>]          --</span><br><span class="line">│    │    └─MaxPool2d: <span class="number">3</span>-<span class="number">17</span>              [<span class="number">1</span>, <span class="number">256</span>, <span class="number">30</span>, <span class="number">30</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">18</span>                 [<span class="number">1</span>, <span class="number">512</span>, <span class="number">30</span>, <span class="number">30</span>]          (<span class="number">1</span>,<span class="number">180</span>,<span class="number">160</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">19</span>                   [<span class="number">1</span>, <span class="number">512</span>, <span class="number">30</span>, <span class="number">30</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">20</span>                 [<span class="number">1</span>, <span class="number">512</span>, <span class="number">30</span>, <span class="number">30</span>]          (<span class="number">2</span>,<span class="number">359</span>,<span class="number">808</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">21</span>                   [<span class="number">1</span>, <span class="number">512</span>, <span class="number">30</span>, <span class="number">30</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">22</span>                 [<span class="number">1</span>, <span class="number">512</span>, <span class="number">30</span>, <span class="number">30</span>]          (<span class="number">2</span>,<span class="number">359</span>,<span class="number">808</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">23</span>                   [<span class="number">1</span>, <span class="number">512</span>, <span class="number">30</span>, <span class="number">30</span>]          --</span><br><span class="line">│    │    └─MaxPool2d: <span class="number">3</span>-<span class="number">24</span>              [<span class="number">1</span>, <span class="number">512</span>, <span class="number">15</span>, <span class="number">15</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">25</span>                 [<span class="number">1</span>, <span class="number">512</span>, <span class="number">15</span>, <span class="number">15</span>]          (<span class="number">2</span>,<span class="number">359</span>,<span class="number">808</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">26</span>                   [<span class="number">1</span>, <span class="number">512</span>, <span class="number">15</span>, <span class="number">15</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">27</span>                 [<span class="number">1</span>, <span class="number">512</span>, <span class="number">15</span>, <span class="number">15</span>]          (<span class="number">2</span>,<span class="number">359</span>,<span class="number">808</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">28</span>                   [<span class="number">1</span>, <span class="number">512</span>, <span class="number">15</span>, <span class="number">15</span>]          --</span><br><span class="line">│    │    └─Conv2d: <span class="number">3</span>-<span class="number">29</span>                 [<span class="number">1</span>, <span class="number">512</span>, <span class="number">15</span>, <span class="number">15</span>]          (<span class="number">2</span>,<span class="number">359</span>,<span class="number">808</span>)</span><br><span class="line">│    │    └─ReLU: <span class="number">3</span>-<span class="number">30</span>                   [<span class="number">1</span>, <span class="number">512</span>, <span class="number">15</span>, <span class="number">15</span>]          --</span><br><span class="line">│    │    └─MaxPool2d: <span class="number">3</span>-<span class="number">31</span>              [<span class="number">1</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>]            --</span><br><span class="line">│    └─AdaptiveAvgPool2d: <span class="number">2</span>-<span class="number">2</span>            [<span class="number">1</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>]            --</span><br><span class="line">│    └─Sequential: <span class="number">2</span>-<span class="number">3</span>                   [<span class="number">1</span>, <span class="number">2</span>]                    --</span><br><span class="line">│    │    └─Linear: <span class="number">3</span>-<span class="number">32</span>                 [<span class="number">1</span>, <span class="number">2</span>]                    <span class="number">50</span>,<span class="number">178</span></span><br><span class="line">│    │    └─Softmax: <span class="number">3</span>-<span class="number">33</span>                [<span class="number">1</span>, <span class="number">2</span>]                    --     --</span><br><span class="line">==========================================================================================</span><br><span class="line">Total params: <span class="number">14</span>,<span class="number">764</span>,<span class="number">866</span></span><br><span class="line">Trainable params: <span class="number">50</span>,<span class="number">178</span></span><br><span class="line">Non-trainable params: <span class="number">14</span>,<span class="number">714</span>,<span class="number">688</span></span><br><span class="line">Total mult-adds (G): <span class="number">17.99</span></span><br><span class="line">==========================================================================================</span><br></pre></td></tr></table></figure>
<blockquote>
<p>this model contain around 15 million total parameters, but only 50k of them are trainable - those are the weights of classification layer.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">&#x27;data/cats_dogs.pth&#x27;</span></span><br><span class="line">net = TransferVgg16()</span><br><span class="line">summary(net, input_size=(<span class="number">1</span>, <span class="number">3</span>, <span class="number">244</span>, <span class="number">244</span>))</span><br><span class="line">sub_dataset(<span class="number">2000</span>)</span><br><span class="line">hist = train(net, training_dataloader, test_dataloader)</span><br><span class="line">plot_acc_loss(hist)</span><br><span class="line">torch.save(net, path)</span><br><span class="line"></span><br><span class="line">epoch: <span class="number">10</span></span><br><span class="line">------------------------------------------</span><br><span class="line">train loss: <span class="number">0.315983</span>   [<span class="number">0</span>/<span class="number">1500</span>]</span><br><span class="line">train loss: <span class="number">0.319530</span>   [<span class="number">320</span>/<span class="number">1500</span>]</span><br><span class="line">train loss: <span class="number">0.315883</span>   [<span class="number">640</span>/<span class="number">1500</span>]</span><br><span class="line">train loss: <span class="number">0.315727</span>   [<span class="number">960</span>/<span class="number">1500</span>]</span><br><span class="line">train loss: <span class="number">0.315908</span>   [<span class="number">1280</span>/<span class="number">1500</span>]</span><br><span class="line">train_loss: <span class="number">0.323956</span>     train_acc: <span class="number">0.999333</span>     <span class="number">1500</span></span><br><span class="line">val_loss: <span class="number">0.322157</span>     val_acc: <span class="number">0.994000</span>     <span class="number">500</span></span><br></pre></td></tr></table></figure>
<p><img src="18.png" alt="18" style="zoom:60%;" /></p>
<h3 id="fine-tuning-transfer-learning">Fine-tuning transfer learning</h3>
<blockquote>
<p>In the previous section, we have trained the final classifier layer to classify images in our own dataset. However, we did not re-train the feature extractor, and our model relied on the features that the model has learned on ImageNet data. If your objects visually differ from ordinary ImageNet images, this combination of features might not work best. Thus it makes sense to start training convolutional layers as well.</p>
<p>we can unfreeze the convolutional filter parameters that we have previously frozen.</p>
</blockquote>
<h2 id="other-computer-vision-models">Other computer vision models</h2>
<p>VGG-16 is one of the simplest computer vision architectures. <code>torchvision</code> package provides many more pre-trained networks. The most frequently used ones among those are <strong>ResNet</strong> architectures, developed by Microsoft, and <strong>Inception</strong> by Google.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
              <a href="/tags/python/" rel="tag"># python</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/06/22/PyTorch-Transform/" rel="prev" title="Building the model layers">
                  <i class="fa fa-chevron-left"></i> Building the model layers
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/06/28/MobileNet/" rel="next" title="MobileNet">
                  MobileNet <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>





<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2017 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiuYang</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">706k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">10:41</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;js&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/quicklink@2.1.0/dist/quicklink.umd.js"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{&quot;enable&quot;:true,&quot;home&quot;:true,&quot;archive&quot;:true,&quot;delay&quot;:true,&quot;timeout&quot;:3000,&quot;priority&quot;:true,&quot;ignores&quot;:null,&quot;url&quot;:&quot;https:&#x2F;&#x2F;ly1998117.github.io&#x2F;2021&#x2F;06&#x2F;24&#x2F;Computer-Vision-PyTorch&#x2F;&quot;}</script>
  <script src="/js/third-party/quicklink.js"></script>



  <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
  <script src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
  <script async src="/js/cursor/explosion.js"></script>

</body>
</html>
