<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;ly1998117.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Gemini&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:true,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:true,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;},&quot;path&quot;:&quot;&#x2F;search.xml&quot;,&quot;localsearch&quot;:{&quot;enable&quot;:true,&quot;trigger&quot;:&quot;auto&quot;,&quot;top_n_per_article&quot;:1,&quot;unescape&quot;:false,&quot;preload&quot;:false}}</script>
<meta name="description" content="Chaper 1 Introducing deep learning and the PyTorch Library  That general class of algorithms we’re talking about falls under the AI subcategory of deep learning, which deals with training mathematical">
<meta property="og:type" content="article">
<meta property="og:title" content="Part 1 Core PyTorch">
<meta property="og:url" content="https://ly1998117.github.io/2021/07/18/Core-PyTorch/index.html">
<meta property="og:site_name" content="LiuYang&#39;s Blog">
<meta property="og:description" content="Chaper 1 Introducing deep learning and the PyTorch Library  That general class of algorithms we’re talking about falls under the AI subcategory of deep learning, which deals with training mathematical">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ly1998117.github.io/2021/07/18/Core-PyTorch/1.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/07/18/Core-PyTorch/2.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/07/18/Core-PyTorch/3.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/07/18/Core-PyTorch/4.png">
<meta property="og:image" content="https://ly1998117.github.io/2021/07/18/Core-PyTorch/5.png">
<meta property="article:published_time" content="2021-07-18T07:02:16.000Z">
<meta property="article:modified_time" content="2021-07-19T13:06:06.086Z">
<meta property="article:author" content="LiuYang">
<meta property="article:tag" content="PyTorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ly1998117.github.io/2021/07/18/Core-PyTorch/1.png">


<link rel="canonical" href="https://ly1998117.github.io/2021/07/18/Core-PyTorch/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;https:&#x2F;&#x2F;ly1998117.github.io&#x2F;2021&#x2F;07&#x2F;18&#x2F;Core-PyTorch&#x2F;&quot;,&quot;path&quot;:&quot;2021&#x2F;07&#x2F;18&#x2F;Core-PyTorch&#x2F;&quot;,&quot;title&quot;:&quot;Part 1 Core PyTorch&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>Part 1 Core PyTorch | LiuYang's Blog</title><script src="/js/config.js"></script>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">LiuYang's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">26</span></a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">13</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#chaper-1-introducing-deep-learning-and-the-pytorch-library"><span class="nav-number">1.</span> <span class="nav-text">Chaper 1 Introducing deep learning and the PyTorch Library</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#the-deep-learning-revolution"><span class="nav-number">1.1.</span> <span class="nav-text">The deep learning revolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pytorch-for-deep-learning"><span class="nav-number">1.2.</span> <span class="nav-text">PyTorch for deep learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hardware-and-software-requirements"><span class="nav-number">1.3.</span> <span class="nav-text">Hardware and software requirements</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#chapter-2-pretrained-networks"><span class="nav-number">2.</span> <span class="nav-text">Chapter 2 Pretrained Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#a-pretrained-network-that-recognizes-the-subject-of-an-image"><span class="nav-number">2.1.</span> <span class="nav-text">A pretrained network that recognizes the subject of an image</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#obtaining-a-pretrained-network-for-image-recognition"><span class="nav-number">2.1.1.</span> <span class="nav-text">Obtaining a pretrained network for image recognition</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#alexnet"><span class="nav-number">2.1.2.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#resnet"><span class="nav-number">2.1.3.</span> <span class="nav-text">ResNet</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiuYang"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">LiuYang</p>
  <div class="site-description" itemprop="description">人与人的悲欢并不相通</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">53</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.macwk.com/" title="https:www.macwk.com&#x2F;" rel="noopener" target="_blank">Macwk</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ly1998117.github.io/2021/07/18/Core-PyTorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="LiuYang">
      <meta itemprop="description" content="人与人的悲欢并不相通">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LiuYang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Part 1 Core PyTorch
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-07-18 15:02:16" itemprop="dateCreated datePublished" datetime="2021-07-18T15:02:16+08:00">2021-07-18</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-07-19 21:06:06" itemprop="dateModified" datetime="2021-07-19T21:06:06+08:00">2021-07-19</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Learning-with-PyTorch/" itemprop="url" rel="index"><span itemprop="name">Deep Learning with PyTorch</span></a>
        </span>
    </span>

  
      </div>
      <div class="post-meta">
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>10 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h2 id="chaper-1-introducing-deep-learning-and-the-pytorch-library">Chaper 1 <em>Introducing deep learning and the PyTorch Library</em></h2>
<blockquote>
<p>That general class of algorithms we’re talking about falls under the AI subcategory of <em>deep learning</em>, which deals with training mathematical entities named <em>deep neural net- works</em> by presenting instructive examples.</p>
</blockquote>
<span id="more"></span>
<ul>
<li>How deep learning changes our approach to machine learning</li>
<li>Understanding why PyTorch is a good fit for deep learning</li>
<li>Examining a typical deep learning project</li>
<li>The hardware you’ll need to follow along with the examples</li>
</ul>
<h3 id="the-deep-learning-revolution">The deep learning revolution</h3>
<p>Until the last decade, the broader class of systems that fell under the label machine learning relied heavily on feature engineering. Features are transformations on input data that facilitate a downstream algorithm, like a classi- fier, to produce correct outcomes on new data. Feature engineering consists of com- ing up with the right transformations so that the downstream algorithm can solve a task.</p>
<p>The ability of a neural network to ingest data and extract useful representations on the basis of examples is what makes deep learning so powerful. The focus of deep learning practitioners is not so much on handcrafting those repre- sentations, but on operating on a mathematical entity so that it discovers representa- tions from the training data autonomously. Often, these automatically created features are better than those that are handcrafted!</p>
<p><img src="1.png" alt="1" style="zoom:40%;" /></p>
<center>
Figure 1.1 Deep learning exchanges the need to handcraft features for an increase in data and computational requirements.
</center>
<p>On the right side of figure 1.1, we see a practitioner busy defining engineering features and feeding them to a learning algorithm; the results on the task will be as good as the features the practitioner engineers.</p>
<p>On the left, with deep learning, the raw data is fed to an algorithm that extracts hierarchical features automatically, guided by the optimization of its own performance on the task; the results will be as good as the ability of the practitioner to drive the algorithm toward its goal.</p>
<p>we already get a glimpse of what we need to execute successful deep learning:</p>
<ul>
<li>We need a way to ingest whatever data we have at hand.</li>
<li>We somehow need to define the deep learning machine.</li>
<li>We must have an automated way, <em>training</em>, to obtain useful representations and make the machine produce desired outputs.</li>
</ul>
<h3 id="pytorch-for-deep-learning">PyTorch for deep learning</h3>
<p>PyTorch is a library for Python programs that facilitates building deep learning proj- ects. It emphasizes flexibility and allows deep learning models to be expressed in idiomatic Python. PyTorch provides a core data structure, the<code>tensor</code>, which is a multidimensional array that shares many similarities with NumPy arrays. Around that foundation, PyTorch comes with features to perform accelerated mathematical operations on dedicated hardware, which makes it convenient to design neural network architectures and train them on individual machines or parallel computing resources.</p>
<p>PyTorch offers some things that make it particularly relevant for deep learning:</p>
<ul>
<li>it provides accelerated computation using graphical processing units (GPUs), often yielding speedups in the range of 50x over doing the same calculation on a CPU.</li>
<li>PyTorch provides facilities that support numerical optimization on generic mathematical expressions, which deep learning uses for training.</li>
<li>PyTorch has been equipped with a high-performance C++ runtime that can be used to deploy models for inference without relying on Python, and can be used for designing and training models in C++.</li>
</ul>
<p>PyTorch has made huge inroads with the research and teaching communities, thanks to its ease of use, and has picked up momentum since, as researchers and graduates train students and move to industry.</p>
<p>### An overview of how PyTorch supports deep learning projects</p>
<p>Actually, for performance reasons, most of PyTorch is written in C++ and CUDA (www.geforce.com/hardware/technology/cuda), a C++-like language from NVIDIA that can be compiled to run with massive parallelism on GPUs. most of the time we’ll interact with PyTorch from Python, building models, training them, and using the trained models to solve actual problems.</p>
<p>PyTorch provides the ability of tensors to keep track of the operations performed on them and to analyti- cally compute derivatives of an output of a computation with respect to any of its inputs. Figure 1.2 shows a standard setup that loads data, trains a model, and then deploys that model to production.</p>
<p><img src="2.png" alt="1" style="zoom:40%;" /></p>
<center>
Figure 1.2 Basic, high-level structure of a PyTorch project, with data loading, training, and deployment to production
</center>
<p>The core PyTorch modules for building neural networks are located in <code>torch.nn</code>, which provides common neural network layers and other architectural components. Fully connected layers, convolutional layers, activation functions, and loss functions can all be found here. This bridge between our custom data (in whatever format it might be) and a standardized PyTorch tensor is the Dataset class PyTorch provides <code>torch.utils.data.</code></p>
<p>PyTorch readily provides all that magic in the DataLoader class. Its instances can spawn child processes to load data from a dataset in the background so that it’s ready and waiting for the training loop as soon as the loop can use it.</p>
<p>It’s increasingly common to use more elaborate hardware like multiple GPUs or multiple machines that contribute their resources to training a large model, as seen in the bottom center of figure 1.2. In those cases, <code>torch.nn.parallel.DistributedDataParallel</code> and the<code>torch.distributed</code> submodule can be employed to use the additional hardware.</p>
<h3 id="hardware-and-software-requirements">Hardware and software requirements</h3>
<p>we anticipate that completing a full training run for the more advanced examples in part 2 will require a CUDA-capable GPU. The default parameters used in part 2 assume a GPU with 8 GB of RAM (we suggest an NVIDIA GTX 1070 or better), but those can be adjusted if your hardware has less RAM available.</p>
<p><a target="_blank" rel="noopener" href="https://dawn.cs.stanford.edu/benchmark/index.html">DAWNBench</a> is an interesting initiative from Stanford University aimed at providing benchmarks on training time and cloud computing costs related to common deep learning tasks on publicly available datasets.</p>
<p>Full working code for all listings from the book can be found at the book’s website (www.manning.com/books/deep-learning-with-pytorch) and in our repository on GitHub (https://github.com/deep-learning-with-pytorch/dlwpt-code).</p>
<h2 id="chapter-2-pretrained-networks">Chapter 2 Pretrained Networks</h2>
<ul>
<li>Running pretrained image-recognition models</li>
<li>An introduction to GANs and CycleGAN</li>
<li>Captioning models that can produce text descriptions of images</li>
<li>Sharing models through Torch Hub</li>
</ul>
<p>We are going to learn how to use the work of the best researchers in the field by downloading and running very interesting models that have already been trained on open, large-scale datasets.</p>
<p>In this chapter, we will explore three popular pretrained models:</p>
<ul>
<li>a model that can label an image according to its content</li>
<li>another that can fabricate a new image from a real image --- GAN</li>
<li>a model that can describe the content of an image using proper English sentences.</li>
</ul>
<p>We will learn how to load and run these pretrained models in PyTorch, and we will introduce PyTorch Hub, a set of tools through which PyTorch models like the pretrained ones we’ll discuss can be easily made available through a uniform interface. Along the way, we’ll discuss data sources, define terminology like <em>label</em>, and attend a zebra rodeo.</p>
<h3 id="a-pretrained-network-that-recognizes-the-subject-of-an-image"><em>A pretrained network that recognizes the subject of an image</em></h3>
<p>we’ll run a state-of-the-art deep neural network that was pretrained on an object-recognition task.</p>
<p>The pretrained network we’ll explore here was trained on a subset of the <strong><a target="_blank" rel="noopener" href="http://imagenet.stanford.edu">ImageNet dataset</a>.</strong> ImageNet is a very large dataset of over 14 mil- lion images maintained by Stanford University. All of the images are labeled with a hier- archy of nouns that come from the <strong><a target="_blank" rel="noopener" href="http://wordnet.princeton.edu">WordNet dataset</a>,</strong> which is in turn a large lexical database of the English language. the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) has gained popularity since its inception in 2010. This particular competition is based on a few tasks, which can vary each year, such as image classification (telling what object categories the image contains), object localization (identifying objects’ position in images), object detection (identifying and labeling objects in images), scene classifica- tion (classifying a situation in an image), and scene parsing (segmenting an image into regions associated with semantic categories, such as cow, house, cheese, hat).</p>
<p><img src="3.png" alt="3" style="zoom:40%;" /></p>
<center>
Figure 2.1 A small sample of ImageNet images
</center>
<p><img src="4.png" alt="4" style="zoom:50%;" /></p>
<center>
Figure 2.2 The inference process
</center>
<p>We are going to end up being able to take our own images and feed them into our pretrained model, as pictured in figure 2.2. This will result in a list of predicted labels for that image, which we can then examine to see what the model thinks our image is. Some images will have predictions that are accurate, and others will not!</p>
<h4 id="obtaining-a-pretrained-network-for-image-recognition"><em>Obtaining a pretrained network for image recognition</em></h4>
<p><a target="_blank" rel="noopener" href="https://github.com/pytorch/vision">TorchVision project</a>, which contains a few of the best-performing neural network architectures for com- puter vision, such as <a target="_blank" rel="noopener" href="http://mng.bz/lo6z">AlexNet</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/%201512.03385.pdf">ResNet</a>, and <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.00567.pdf">Inception v3</a>.</p>
<p>For now, let’s load up and run two networks: first AlexNet, one of the early breakthrough networks for image recognition; and then a residual network, ResNet for short, which won the ImageNet classification, detection, and localization competitions, among others, in 2015. The predefined models can be found in <code>torchvision.models</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> torch <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># In[2]:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">dir</span>(models)</span><br><span class="line"><span class="comment"># Out[2]:</span></span><br><span class="line">[<span class="string">&#x27;AlexNet&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;DenseNet&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Inception3&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ResNet&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;SqueezeNet&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;VGG&#x27;</span>,</span><br><span class="line"> ...</span><br><span class="line"> <span class="string">&#x27;alexnet&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;densenet&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;densenet121&#x27;</span>,</span><br><span class="line"> ...</span><br><span class="line"> <span class="string">&#x27;resnet&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;resnet101&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;resnet152&#x27;</span>,</span><br><span class="line"> ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>The capitalized names refer to Python classes that implement a number of popular models. The lowercase names are convenience functions that return models instantiated from those classes, sometimes with different parameter sets. For instance, resnet101 returns an instance of ResNet with 101 layers, resnet18 has 18 layers, and so on. We’ll now turn our attention to AlexNet.</p>
<h4 id="alexnet"><em>AlexNet</em></h4>
<p>The AlexNet architecture won the 2012 ILSVRC by a large margin, with a top-5 test error rate (that is, the correct label must be in the top 5 predictions) of 15.4%. This was a defining moment in the history of computer vision: the moment when the community started to realize the potential of deep learning for vision tasks. That leap was followed by constant improvement, with more modern architectures and training methods getting top-5 error rates as low as 3%.</p>
<p><img src="5.png" alt="4" style="zoom:40%;" /></p>
<center>
Figure 2.3 The AlexNet architecture
</center>
<p>In figure 2.3, input images come in from the left and go through five stacks of filters, each producing a number of output images. After each filter, the images are reduced in size, as annotated. The images produced by the last stack of filters are laid out as a 4,096-element 1D vector and classified to produce 1,000 output probabilities, one for each output class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In[3]:</span></span><br><span class="line">alexnet = models.AlexNet()</span><br></pre></td></tr></table></figure>
<p>Practically speaking, assuming we have an input object of the right type, we can run the forward pass with <code>output = alexnet(input)</code></p>
<h4 id="resnet">ResNet</h4>
<p>Using the resnet101 function, we’ll now instantiate a 101-layer convolutional neural network. Just to put things in perspective, before the advent of residual networks in 2015, achieving stable training at such depths was considered extremely hard. Residual networks pulled a trick that made it possible, and by doing so, beat several benchmarks in one sweep that year.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># In[4]:</span></span><br><span class="line">resnet = models.resnet101(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># In[5]:</span></span><br><span class="line">resnet</span><br><span class="line"><span class="comment"># Out[5]:</span></span><br><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                  bias=<span class="literal">False</span>)</span><br><span class="line">  (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>,</span><br><span class="line">                     track_running_stats=<span class="literal">True</span>)</span><br><span class="line">  (relu): ReLU(inplace)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>,</span><br><span class="line">ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Bottleneck(</span><br><span class="line">      ...</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">  (avgpool): AvgPool2d(kernel_size=<span class="number">7</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">  (fc): Linear(in_features=<span class="number">2048</span>, out_features=<span class="number">1000</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>If we scroll down, we’ll see a lot of Bottleneck modules repeating one after the other (101 of them!), containing convolutions and other modules. That’s the anatomy of a <strong>typical deep neural network for computer vision</strong>: a more or less sequential cascade of filters and nonlinear functions, ending with a layer (fc) producing scores for each of the 1,000 output classes (out_features).</p>
<p>the torchvision module provides transforms, which allow us to quickly define pipelines of basic preprocessing functions:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from torchvision import transforms</span><br><span class="line">preprocess = transforms.Compose([</span><br><span class="line">				transforms.Resize(256),</span><br><span class="line">				transforms.CenterCrop(224),</span><br><span class="line">				transforms.ToTensor().</span><br><span class="line">				transforms.Normalize(</span><br><span class="line">								mean = [0.485, 0.456, 0.406]</span><br><span class="line">				)</span><br><span class="line">])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/07/17/ML8/" rel="prev" title="机器学习 by 李宏毅(7-2)">
                  <i class="fa fa-chevron-left"></i> 机器学习 by 李宏毅(7-2)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/07/19/pmset/" rel="next" title="通过 pmset 工具管理 masOS 睡眠">
                  通过 pmset 工具管理 masOS 睡眠 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>





<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2017 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LiuYang</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">752k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">11:24</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="/js/third-party/search/local-search.js"></script>






  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;js&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/quicklink@2.1.0/dist/quicklink.umd.js"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{&quot;enable&quot;:true,&quot;home&quot;:true,&quot;archive&quot;:true,&quot;delay&quot;:true,&quot;timeout&quot;:3000,&quot;priority&quot;:true,&quot;ignores&quot;:null,&quot;url&quot;:&quot;https:&#x2F;&#x2F;ly1998117.github.io&#x2F;2021&#x2F;07&#x2F;18&#x2F;Core-PyTorch&#x2F;&quot;}</script>
  <script src="/js/third-party/quicklink.js"></script>



  <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;" ></canvas>
  <script src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
  <script async src="/js/cursor/explosion.js"></script>

</body>
</html>
